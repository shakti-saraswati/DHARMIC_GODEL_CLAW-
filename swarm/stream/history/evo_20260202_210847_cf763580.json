{
  "id": "evo_20260202_210847_cf763580",
  "timestamp": "2026-02-02T21:08:47.178503",
  "state": "write",
  "agent": "writer",
  "action": "implementation_complete",
  "parent_id": "evo_20260202_210701_de14ceea",
  "fitness": null,
  "files_changed": [
    "swarm/knowledge_base.py",
    "swarm/agents/base_agent.py",
    "swarm/agents/proposer.py"
  ],
  "metadata": {
    "files": [
      {
        "path": "swarm/knowledge_base.py",
        "action": "create",
        "content": "\"\"\"Core knowledge base with pattern storage, scoring, and sharing capabilities.\"\"\"\n\nimport json\nimport sqlite3\nimport threading\nimport time\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Any, Tuple\nfrom datetime import datetime, timedelta\n\n\n@dataclass\nclass Pattern:\n    \"\"\"Represents a knowledge pattern with metadata.\"\"\"\n    id: str\n    content: str\n    pattern_type: str\n    score: float\n    success_count: int\n    failure_count: int\n    created_at: float\n    updated_at: float\n    tags: List[str]\n    context: Dict[str, Any]\n\n\nclass KnowledgeBase:\n    \"\"\"Thread-safe knowledge base for storing and retrieving patterns.\"\"\"\n    \n    def __init__(self, db_path: str = \"knowledge.db\"):\n        \"\"\"Initialize knowledge base with SQLite backend.\"\"\"\n        self.db_path = db_path\n        self.lock = threading.RLock()\n        self._init_db()\n    \n    def _init_db(self) -> None:\n        \"\"\"Initialize database schema.\"\"\"\n        with sqlite3.connect(self.db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS patterns (\n                    id TEXT PRIMARY KEY,\n                    content TEXT NOT NULL,\n                    pattern_type TEXT NOT NULL,\n                    score REAL NOT NULL DEFAULT 0.0,\n                    success_count INTEGER NOT NULL DEFAULT 0,\n                    failure_count INTEGER NOT NULL DEFAULT 0,\n                    created_at REAL NOT NULL,\n                    updated_at REAL NOT NULL,\n                    tags TEXT NOT NULL DEFAULT '[]',\n                    context TEXT NOT NULL DEFAULT '{}'\n                )\n            \"\"\")\n            conn.execute(\"\"\"\n                CREATE INDEX IF NOT EXISTS idx_pattern_type \n                ON patterns(pattern_type)\n            \"\"\")\n            conn.execute(\"\"\"\n                CREATE INDEX IF NOT EXISTS idx_score \n                ON patterns(score DESC)\n            \"\"\")\n    \n    def store_pattern(self, pattern: Pattern) -> bool:\n        \"\"\"Store or update a pattern in the knowledge base.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    conn.execute(\"\"\"\n                        INSERT OR REPLACE INTO patterns \n                        (id, content, pattern_type, score, success_count, \n                         failure_count, created_at, updated_at, tags, context)\n                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n                    \"\"\", (\n                        pattern.id, pattern.content, pattern.pattern_type,\n                        pattern.score, pattern.success_count, pattern.failure_count,\n                        pattern.created_at, pattern.updated_at,\n                        json.dumps(pattern.tags), json.dumps(pattern.context)\n                    ))\n                return True\n            except sqlite3.Error:\n                return False\n    \n    def get_pattern(self, pattern_id: str) -> Optional[Pattern]:\n        \"\"\"Retrieve a pattern by ID.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\n                        \"SELECT * FROM patterns WHERE id = ?\", (pattern_id,)\n                    )\n                    row = cursor.fetchone()\n                    if row:\n                        return self._row_to_pattern(row)\n                return None\n            except sqlite3.Error:\n                return None\n    \n    def get_patterns_by_type(self, pattern_type: str, limit: int = 100) -> List[Pattern]:\n        \"\"\"Retrieve patterns by type, ordered by score.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\"\"\"\n                        SELECT * FROM patterns \n                        WHERE pattern_type = ? \n                        ORDER BY score DESC \n                        LIMIT ?\n                    \"\"\", (pattern_type, limit))\n                    return [self._row_to_pattern(row) for row in cursor.fetchall()]\n            except sqlite3.Error:\n                return []\n    \n    def get_top_patterns(self, limit: int = 50) -> List[Pattern]:\n        \"\"\"Get top patterns by score across all types.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\"\"\"\n                        SELECT * FROM patterns \n                        ORDER BY score DESC \n                        LIMIT ?\n                    \"\"\", (limit,))\n                    return [self._row_to_pattern(row) for row in cursor.fetchall()]\n            except sqlite3.Error:\n                return []\n    \n    def update_pattern_score(self, pattern_id: str, success: bool) -> bool:\n        \"\"\"Update pattern score based on success/failure.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    # Get current pattern\n                    cursor = conn.execute(\n                        \"SELECT success_count, failure_count FROM patterns WHERE id = ?\",\n                        (pattern_id,)\n                    )\n                    row = cursor.fetchone()\n                    if not row:\n                        return False\n                    \n                    success_count, failure_count = row\n                    \n                    # Update counts\n                    if success:\n                        success_count += 1\n                    else:\n                        failure_count += 1\n                    \n                    # Calculate new score (success rate with smoothing)\n                    total = success_count + failure_count\n                    score = (success_count + 1) / (total + 2)  # Laplace smoothing\n                    \n                    # Update database\n                    conn.execute(\"\"\"\n                        UPDATE patterns \n                        SET success_count = ?, failure_count = ?, \n                            score = ?, updated_at = ?\n                        WHERE id = ?\n                    \"\"\", (success_count, failure_count, score, time.time(), pattern_id))\n                    \n                return True\n            except sqlite3.Error:\n                return False\n    \n    def search_patterns(self, query: str, pattern_type: Optional[str] = None) -> List[Pattern]:\n        \"\"\"Search patterns by content similarity.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    if pattern_type:\n                        cursor = conn.execute(\"\"\"\n                            SELECT * FROM patterns \n                            WHERE pattern_type = ? AND content LIKE ?\n                            ORDER BY score DESC\n                        \"\"\", (pattern_type, f\"%{query}%\"))\n                    else:\n                        cursor = conn.execute(\"\"\"\n                            SELECT * FROM patterns \n                            WHERE content LIKE ?\n                            ORDER BY score DESC\n                        \"\"\", (f\"%{query}%\",))\n                    \n                    return [self._row_to_pattern(row) for row in cursor.fetchall()]\n            except sqlite3.Error:\n                return []\n    \n    def get_patterns_by_tags(self, tags: List[str]) -> List[Pattern]:\n        \"\"\"Get patterns that contain any of the specified tags.\"\"\"\n        with self.lock:\n            try:\n                patterns = []\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\"SELECT * FROM patterns ORDER BY score DESC\")\n                    for row in cursor.fetchall():\n                        pattern = self._row_to_pattern(row)\n                        if any(tag in pattern.tags for tag in tags):\n                            patterns.append(pattern)\n                return patterns\n            except sqlite3.Error:\n                return []\n    \n    def cleanup_old_patterns(self, days: int = 30) -> int:\n        \"\"\"Remove patterns older than specified days with low scores.\"\"\"\n        cutoff_time = time.time() - (days * 24 * 60 * 60)\n        \n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\"\"\"\n                        DELETE FROM patterns \n                        WHERE updated_at < ? AND score < 0.3\n                    \"\"\", (cutoff_time,))\n                    return cursor.rowcount\n            except sqlite3.Error:\n                return 0\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get knowledge base statistics.\"\"\"\n        with self.lock:\n            try:\n                with sqlite3.connect(self.db_path) as conn:\n                    cursor = conn.execute(\"\"\"\n                        SELECT \n                            COUNT(*) as total_patterns,\n                            AVG(score) as avg_score,\n                            pattern_type,\n                            COUNT(*) as type_count\n                        FROM patterns \n                        GROUP BY pattern_type\n                    \"\"\")\n                    \n                    type_stats = {}\n                    total = 0\n                    total_score = 0.0\n                    \n                    for row in cursor.fetchall():\n                        if len(row) == 4:  # GROUP BY query\n                            _, _, pattern_type, count = row\n                            type_stats[pattern_type] = count\n                            total += count\n                        else:  # Aggregate query\n                            total, total_score = row[:2]\n                    \n                    # Get overall stats\n                    cursor = conn.execute(\"SELECT COUNT(*), AVG(score) FROM patterns\")\n                    row = cursor.fetchone()\n                    if row:\n                        total, avg_score = row\n                    \n                    return {\n                        \"total_patterns\": total or 0,\n                        \"average_score\": avg_score or 0.0,\n                        \"patterns_by_type\": type_stats\n                    }\n            except sqlite3.Error:\n                return {\"total_patterns\": 0, \"average_score\": 0.0, \"patterns_by_type\": {}}\n    \n    def export_patterns(self, file_path: str) -> bool:\n        \"\"\"Export all patterns to JSON file.\"\"\"\n        try:\n            patterns = self.get_top_patterns(limit=10000)  # Get all\n            data = [asdict(pattern) for pattern in patterns]\n            \n            Path(file_path).parent.mkdir(parents=True, exist_ok=True)\n            with open(file_path, 'w') as f:\n                json.dump(data, f, indent=2)\n            return True\n        except (IOError, json.JSONEncodeError):\n            return False\n    \n    def import_patterns(self, file_path: str) -> int:\n        \"\"\"Import patterns from JSON file.\"\"\"\n        try:\n            with open(file_path, 'r') as f:\n                data = json.load(f)\n            \n            count = 0\n            for pattern_data in data:\n                pattern = Pattern(**pattern_data)\n                if self.store_pattern(pattern):\n                    count += 1\n            \n            return count\n        except (IOError, json.JSONDecodeError, TypeError):\n            return 0\n    \n    def _row_to_pattern(self, row: Tuple) -> Pattern:\n        \"\"\"Convert database row to Pattern object.\"\"\"\n        return Pattern(\n            id=row[0],\n            content=row[1],\n            pattern_type=row[2],\n            score=row[3],\n            success_count=row[4],\n            failure_count=row[5],\n            created_at=row[6],\n            updated_at=row[7],\n            tags=json.loads(row[8]) if row[8] else [],\n            context=json.loads(row[9]) if row[9] else {}\n        )"
      },
      {
        "path": "swarm/agents/base_agent.py",
        "action": "modify",
        "content": "\"\"\"Base agent class for the DHARMIC GODEL CLAW swarm.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, List, Any, Optional, Union\nimport logging\nimport json\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom ..knowledge.knowledge_base import KnowledgeBase\nfrom ..knowledge.pattern_recorder import PatternRecorder\n\n\nclass BaseAgent(ABC):\n    \"\"\"Base class for all swarm agents.\"\"\"\n    \n    def __init__(self, agent_id: str, config: Dict[str, Any]):\n        \"\"\"Initialize base agent.\n        \n        Args:\n            agent_id: Unique identifier for this agent\n            config: Configuration dictionary\n        \"\"\"\n        self.agent_id = agent_id\n        self.config = config\n        self.logger = logging.getLogger(f\"swarm.{self.__class__.__name__}.{agent_id}\")\n        \n        # Initialize knowledge components\n        kb_path = config.get('knowledge_base_path', 'data/knowledge_base.json')\n        self.knowledge_base = KnowledgeBase(kb_path)\n        \n        patterns_path = config.get('patterns_path', 'data/patterns')\n        self.pattern_recorder = PatternRecorder(patterns_path)\n        \n        self.metrics = {\n            'tasks_completed': 0,\n            'errors_encountered': 0,\n            'patterns_recorded': 0,\n            'knowledge_queries': 0\n        }\n    \n    @abstractmethod\n    def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Process a task and return results.\n        \n        Args:\n            task: Task specification\n            \n        Returns:\n            Task results\n        \"\"\"\n        pass\n    \n    def record_pattern(self, pattern_type: str, data: Dict[str, Any], \n                      success: bool = True) -> None:\n        \"\"\"Record a behavioral pattern for learning.\n        \n        Args:\n            pattern_type: Type of pattern (e.g., 'task_execution', 'error_recovery')\n            data: Pattern data including context and outcome\n            success: Whether this was a successful pattern\n        \"\"\"\n        try:\n            pattern = {\n                'agent_id': self.agent_id,\n                'agent_type': self.__class__.__name__,\n                'pattern_type': pattern_type,\n                'timestamp': datetime.utcnow().isoformat(),\n                'success': success,\n                'data': data\n            }\n            \n            self.pattern_recorder.record_pattern(pattern)\n            self.metrics['patterns_recorded'] += 1\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to record pattern: {e}\")\n    \n    def query_knowledge(self, query: str, context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:\n        \"\"\"Query the knowledge base for relevant information.\n        \n        Args:\n            query: Search query\n            context: Optional context for the query\n            \n        Returns:\n            List of relevant knowledge items\n        \"\"\"\n        try:\n            results = self.knowledge_base.query(query, context or {})\n            self.metrics['knowledge_queries'] += 1\n            return results\n            \n        except Exception as e:\n            self.logger.error(f\"Knowledge query failed: {e}\")\n            return []\n    \n    def add_knowledge(self, knowledge_type: str, content: Dict[str, Any], \n                     tags: Optional[List[str]] = None) -> None:\n        \"\"\"Add new knowledge to the knowledge base.\n        \n        Args:\n            knowledge_type: Type of knowledge (e.g., 'solution', 'error_fix', 'optimization')\n            content: Knowledge content\n            tags: Optional tags for categorization\n        \"\"\"\n        try:\n            knowledge_item = {\n                'type': knowledge_type,\n                'source_agent': self.agent_id,\n                'timestamp': datetime.utcnow().isoformat(),\n                'content': content,\n                'tags': tags or []\n            }\n            \n            self.knowledge_base.add_knowledge(knowledge_item)\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to add knowledge: {e}\")\n    \n    def get_similar_patterns(self, pattern_type: str, context: Dict[str, Any], \n                           limit: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Get similar patterns for learning and adaptation.\n        \n        Args:\n            pattern_type: Type of pattern to search for\n            context: Context to match against\n            limit: Maximum number of patterns to return\n            \n        Returns:\n            List of similar patterns\n        \"\"\"\n        try:\n            return self.pattern_recorder.get_similar_patterns(\n                pattern_type, context, limit\n            )\n        except Exception as e:\n            self.logger.error(f\"Failed to get similar patterns: {e}\")\n            return []\n    \n    def handle_error(self, error: Exception, context: Dict[str, Any]) -> None:\n        \"\"\"Handle and record errors for learning.\n        \n        Args:\n            error: The exception that occurred\n            context: Context in which the error occurred\n        \"\"\"\n        self.metrics['errors_encountered'] += 1\n        self.logger.error(f\"Error in {self.agent_id}: {error}\")\n        \n        # Record error pattern for learning\n        error_data = {\n            'error_type': type(error).__name__,\n            'error_message': str(error),\n            'context': context\n        }\n        \n        self.record_pattern('error', error_data, success=False)\n        \n        # Query for similar error patterns to learn from\n        similar_errors = self.get_similar_patterns('error', error_data)\n        if similar_errors:\n            self.logger.info(f\"Found {len(similar_errors)} similar error patterns\")\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get agent performance metrics.\n        \n        Returns:\n            Dictionary of metrics\n        \"\"\"\n        return {\n            **self.metrics,\n            'agent_id': self.agent_id,\n            'agent_type': self.__class__.__name__\n        }\n    \n    def save_state(self, path: Optional[Union[str, Path]] = None) -> None:\n        \"\"\"Save agent state to disk.\n        \n        Args:\n            path: Optional path to save to, defaults to config path\n        \"\"\"\n        if path is None:\n            path = Path(self.config.get('state_path', f'data/agents/{self.agent_id}_state.json'))\n        \n        state = {\n            'agent_id': self.agent_id,\n            'config': self.config,\n            'metrics': self.metrics,\n            'timestamp': datetime.utcnow().isoformat()\n        }\n        \n        try:\n            Path(path).parent.mkdir(parents=True, exist_ok=True)\n            with open(path, 'w') as f:\n                json.dump(state, f, indent=2)\n        except Exception as e:\n            self.logger.error(f\"Failed to save state: {e}\")\n    \n    def load_state(self, path: Union[str, Path]) -> None:\n        \"\"\"Load agent state from disk.\n        \n        Args:\n            path: Path to load state from\n        \"\"\"\n        try:\n            with open(path, 'r') as f:\n                state = json.load(f)\n            \n            self.metrics.update(state.get('metrics', {}))\n            self.logger.info(f\"Loaded state from {path}\")\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to load state: {e}\")"
      },
      {
        "path": "swarm/agents/proposer.py",
        "action": "modify",
        "content": "\"\"\"\nProposer agent for generating improvement proposals based on learned patterns.\n\"\"\"\n\nimport json\nimport logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Any\nfrom dataclasses import dataclass, asdict\n\nfrom ..core.base_agent import BaseAgent\nfrom ..core.memory import Memory\n\n\n@dataclass\nclass ProposalPattern:\n    \"\"\"Pattern learned from successful proposals.\"\"\"\n    category: str\n    success_rate: float\n    common_keywords: List[str]\n    avg_impact_score: float\n    usage_count: int\n\n\n@dataclass\nclass Proposal:\n    \"\"\"A proposed improvement to the swarm.\"\"\"\n    id: str\n    title: str\n    description: str\n    category: str\n    impact_score: float\n    confidence: float\n    timestamp: str\n    pattern_id: Optional[str] = None\n\n\nclass ProposerAgent(BaseAgent):\n    \"\"\"Agent that generates improvement proposals using learned patterns.\"\"\"\n    \n    def __init__(self, memory: Memory, config: Optional[Dict[str, Any]] = None):\n        \"\"\"Initialize the proposer agent.\n        \n        Args:\n            memory: Shared memory instance\n            config: Optional configuration parameters\n        \"\"\"\n        super().__init__(memory, config)\n        self.logger = logging.getLogger(__name__)\n        self.patterns: Dict[str, ProposalPattern] = {}\n        self.proposal_history: List[Proposal] = []\n        self._load_patterns()\n        \n    def _load_patterns(self) -> None:\n        \"\"\"Load learned patterns from memory.\"\"\"\n        try:\n            patterns_data = self.memory.get('proposer_patterns', {})\n            for pattern_id, pattern_dict in patterns_data.items():\n                self.patterns[pattern_id] = ProposalPattern(**pattern_dict)\n        except Exception as e:\n            self.logger.error(f\"Failed to load patterns: {e}\")\n            \n    def _save_patterns(self) -> None:\n        \"\"\"Save learned patterns to memory.\"\"\"\n        try:\n            patterns_data = {\n                pattern_id: asdict(pattern) \n                for pattern_id, pattern in self.patterns.items()\n            }\n            self.memory.set('proposer_patterns', patterns_data)\n        except Exception as e:\n            self.logger.error(f\"Failed to save patterns: {e}\")\n            \n    def learn_from_feedback(self, proposal_id: str, accepted: bool, \n                          implemented: bool = False, impact: Optional[float] = None) -> None:\n        \"\"\"Learn from proposal feedback to improve future suggestions.\n        \n        Args:\n            proposal_id: ID of the proposal\n            accepted: Whether proposal was accepted\n            implemented: Whether proposal was implemented\n            impact: Measured impact score if available\n        \"\"\"\n        try:\n            # Find the proposal\n            proposal = None\n            for p in self.proposal_history:\n                if p.id == proposal_id:\n                    proposal = p\n                    break\n                    \n            if not proposal:\n                self.logger.warning(f\"Proposal {proposal_id} not found for learning\")\n                return\n                \n            # Update pattern based on feedback\n            if proposal.pattern_id and proposal.pattern_id in self.patterns:\n                pattern = self.patterns[proposal.pattern_id]\n                pattern.usage_count += 1\n                \n                if accepted:\n                    pattern.success_rate = (pattern.success_rate * (pattern.usage_count - 1) + 1.0) / pattern.usage_count\n                else:\n                    pattern.success_rate = (pattern.success_rate * (pattern.usage_count - 1) + 0.0) / pattern.usage_count\n                    \n                if impact is not None:\n                    pattern.avg_impact_score = (pattern.avg_impact_score * (pattern.usage_count - 1) + impact) / pattern.usage_count\n                    \n            self._save_patterns()\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to learn from feedback: {e}\")\n            \n    def _extract_patterns(self, successful_proposals: List[Proposal]) -> None:\n        \"\"\"Extract patterns from successful proposals.\n        \n        Args:\n            successful_proposals: List of proposals that were accepted/implemented\n        \"\"\"\n        try:\n            # Group by category\n            category_groups: Dict[str, List[Proposal]] = {}\n            for proposal in successful_proposals:\n                if proposal.category not in category_groups:\n                    category_groups[proposal.category] = []\n                category_groups[proposal.category].append(proposal)\n                \n            # Create patterns for each category\n            for category, proposals in category_groups.items():\n                if len(proposals) < 2:  # Need at least 2 examples\n                    continue\n                    \n                # Extract common keywords\n                all_words = []\n                for proposal in proposals:\n                    words = proposal.description.lower().split()\n                    all_words.extend(words)\n                    \n                word_counts = {}\n                for word in all_words:\n                    word_counts[word] = word_counts.get(word, 0) + 1\n                    \n                common_keywords = [\n                    word for word, count in word_counts.items() \n                    if count >= len(proposals) * 0.5  # Appears in at least 50% of proposals\n                ][:10]  # Top 10\n                \n                # Calculate average impact\n                avg_impact = sum(p.impact_score for p in proposals) / len(proposals)\n                \n                # Create pattern\n                pattern_id = f\"{category}_{len(self.patterns)}\"\n                pattern = ProposalPattern(\n                    category=category,\n                    success_rate=1.0,  # All examples were successful\n                    common_keywords=common_keywords,\n                    avg_impact_score=avg_impact,\n                    usage_count=len(proposals)\n                )\n                \n                self.patterns[pattern_id] = pattern\n                \n            self._save_patterns()\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to extract patterns: {e}\")\n            \n    def generate_proposal(self, context: Optional[Dict[str, Any]] = None) -> Optional[Proposal]:\n        \"\"\"Generate a new improvement proposal based on learned patterns.\n        \n        Args:\n            context: Optional context information\n            \n        Returns:\n            Generated proposal or None if generation fails\n        \"\"\"\n        try:\n            # Get system state for context\n            system_state = self.memory.get('system_state', {})\n            recent_issues = self.memory.get('recent_issues', [])\n            \n            # Select best pattern based on success rate and relevance\n            best_pattern = None\n            best_score = 0.0\n            \n            for pattern in self.patterns.values():\n                score = pattern.success_rate * pattern.avg_impact_score\n                if score > best_score:\n                    best_score = score\n                    best_pattern = pattern\n                    \n            if not best_pattern:\n                # Generate basic proposal without pattern\n                return self._generate_basic_proposal(context)\n                \n            # Generate proposal based on pattern\n            proposal_id = f\"prop_{datetime.now().isoformat()}\"\n            \n            # Use pattern keywords and category to generate focused proposal\n            if best_pattern.category == \"performance\":\n                title = \"Optimize Performance Based on Metrics\"\n                description = f\"Improve system performance by addressing bottlenecks. Focus areas: {', '.join(best_pattern.common_keywords[:3])}\"\n            elif best_pattern.category == \"reliability\":\n                title = \"Enhance System Reliability\"\n                description = f\"Strengthen error handling and fault tolerance. Key improvements: {', '.join(best_pattern.common_keywords[:3])}\"\n            elif best_pattern.category == \"scalability\":\n                title = \"Improve System Scalability\"\n                description = f\"Enhance ability to handle increased load. Target areas: {', '.join(best_pattern.common_keywords[:3])}\"\n            else:\n                title = f\"Improve {best_pattern.category.title()}\"\n                description = f\"Enhancement in {best_pattern.category} area focusing on: {', '.join(best_pattern.common_keywords[:3])}\"\n                \n            proposal = Proposal(\n                id=proposal_id,\n                title=title,\n                description=description,\n                category=best_pattern.category,\n                impact_score=min(best_pattern.avg_impact_score * 1.1, 10.0),  # Slight optimism\n                confidence=best_pattern.success_rate,\n                timestamp=datetime.now().isoformat(),\n                pattern_id=list(self.patterns.keys())[list(self.patterns.values()).index(best_pattern)]\n            )\n            \n            self.proposal_history.append(proposal)\n            return proposal\n            \n        except Exception as e:\n            self.logger.error(f\"Failed to generate proposal: {e}\")\n            return None\n            \n    def _generate_basic_proposal(self, context: Optional[Dict[str, Any]] = None) -> Proposal:\n        \"\"\"Generate a basic proposal when no patterns are available.\n        \n        Args:\n            context: Optional context information\n            \n        Returns:\n            Basic improvement proposal\n        \"\"\"\n        proposal_id = f\"prop_{datetime.now().isoformat()}\"\n        \n        return Proposal(\n            id=proposal_id,\n            title=\"Improve System Monitoring\",\n            description=\"Add comprehensive logging and metrics collection to better understand system behavior and identify improvement opportunities.\",\n            category=\"monitoring\",\n            impact_score=5.0,\n            confidence=0.7,\n            timestamp=datetime.now().isoformat()\n        )\n        \n    def get_proposal_history(self) -> List[Dict[str, Any]]:\n        \"\"\"Get history of generated proposals.\n        \n        Returns:\n            List of proposal dictionaries\n        \"\"\"\n        return [asdict(proposal) for proposal in self.proposal_history]\n        \n    def get_learned_patterns(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Get all learned patterns.\n        \n        Returns:\n            Dictionary of pattern data\n        \"\"\"\n        return {\n            pattern_id: asdict(pattern) \n            for pattern_id, pattern in self.patterns.items()\n        }\n        \n    def run(self) -> Dict[str, Any]:\n        \"\"\"Main execution method for the proposer agent.\n        \n        Returns:\n            Execution results\n        \"\"\"\n        try:\n            # Generate a new proposal\n            proposal = self.generate_proposal()\n            \n            if proposal:\n                # Store proposal in memory for other agents\n                proposals = self.memory.get('pending_proposals', [])\n                proposals.append(asdict(proposal))\n                self.memory.set('pending_proposals', proposals)\n                \n                return {\n                    'status': 'success',\n                    'proposal_generated': True,\n                    'proposal_id': proposal.id,\n                    'category': proposal.category\n                }\n            else:\n                return {\n                    'status': 'no_proposal',\n                    'proposal_generated': False\n                }\n                \n        except Exception as e:\n            self.logger.error(f\"Proposer agent execution failed: {e}\")\n            return {\n                'status': 'error',\n                'error': str(e),\n                'proposal_generated': False\n            }"
      }
    ]
  }
}