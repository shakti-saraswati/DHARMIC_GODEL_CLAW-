{
  "proposal_id": "PROP-20260204215532",
  "timestamp": "2026-02-04T21:55:32.858256+00:00",
  "overall_result": "FAIL",
  "gates_passed": 4,
  "gates_failed": 20,
  "gates_warned": 4,
  "gates_skipped": 0,
  "total_duration_seconds": 270.69996428489685,
  "gate_results": [
    {
      "gate_id": "1",
      "gate_name": "LINT_FORMAT",
      "result": "fail",
      "duration_seconds": 0.07413291931152344,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Command failed with exit code 1",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "2",
      "gate_name": "TYPE_CHECK",
      "result": "fail",
      "duration_seconds": 0.2948720455169678,
      "stdout": "",
      "stderr": "Unexpected option --strict.\npyright --help for usage\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 4",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "3",
      "gate_name": "SECURITY_SCAN",
      "result": "fail",
      "duration_seconds": 180.01095032691956,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Gate timed out after 180s",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "4",
      "gate_name": "DEPENDENCY_SAFETY",
      "result": "fail",
      "duration_seconds": 68.12442588806152,
      "stdout": "",
      "stderr": "Found 31 known vulnerabilities in 14 packages\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 1",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "5",
      "gate_name": "TEST_COVERAGE",
      "result": "fail",
      "duration_seconds": 20.042335033416748,
      "stdout": "============================================================\nQuick Test - RunPod Setup Verification\n============================================================\n\n[1/4] GPU Check\n  PyTorch: 2.9.1\n  CUDA available: False\n  \u274c CUDA not available\n============================= test session starts ==============================\nplatform darwin -- Python 3.13.5, pytest-8.4.2, pluggy-1.6.0\nrootdir: /Users/dhyana/DHARMIC_GODEL_CLAW\nplugins: jaxtyping-0.3.5, asyncio-1.2.0, anyio-4.9.0, hypothesis-6.151.5, typeguard-4.4.4, cov-7.0.0\nasyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollected 1403 items / 185 errors / 3 skipped\nINTERNALERROR> Traceback (most recent call last):\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 289, in wrap_session\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\nINTERNALERROR>                          ~~~~^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 342, in _main\nINTERNALERROR>     config.hook.pytest_collection(session=session)\nINTERNALERROR>     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_hooks.py\", line 512, in __call__\nINTERNALERROR>     return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\nINTERNALERROR>            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_manager.py\", line 120, in _hookexec\nINTERNALERROR>     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\nINTERNALERROR>            ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\nINTERNALERROR>     raise exception\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 139, in _multicall\nINTERNALERROR>     teardown.throw(exception)\nINTERNALERROR>     ~~~~~~~~~~~~~~^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/logging.py\", line 788, in pytest_collection\nINTERNALERROR>     return (yield)\nINTERNALERROR>             ^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 139, in _multicall\nINTERNALERROR>     teardown.throw(exception)\nINTERNALERROR>     ~~~~~~~~~~~~~~^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/warnings.py\", line 99, in pytest_collection\nINTERNALERROR>     return (yield)\nINTERNALERROR>             ^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 139, in _multicall\nINTERNALERROR>     teardown.throw(exception)\nINTERNALERROR>     ~~~~~~~~~~~~~~^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/config/__init__.py\", line 1450, in pytest_collection\nINTERNALERROR>     return (yield)\nINTERNALERROR>             ^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 121, in _multicall\nINTERNALERROR>     res = hook_impl.function(*args)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 353, in pytest_collection\nINTERNALERROR>     session.perform_collect()\nINTERNALERROR>     ~~~~~~~~~~~~~~~~~~~~~~~^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 813, in perform_collect\nINTERNALERROR>     self.items.extend(self.genitems(node))\nINTERNALERROR>     ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 979, in genitems\nINTERNALERROR>     yield from self.genitems(subnode)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 979, in genitems\nINTERNALERROR>     yield from self.genitems(subnode)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 979, in genitems\nINTERNALERROR>     yield from self.genitems(subnode)\nINTERNALERROR>   [Previous line repeated 3 more times]\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 974, in genitems\nINTERNALERROR>     rep, duplicate = self._collect_one_node(node, handle_dupes)\nINTERNALERROR>                      ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/main.py\", line 839, in _collect_one_node\nINTERNALERROR>     rep = collect_one_node(node)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/runner.py\", line 567, in collect_one_node\nINTERNALERROR>     rep: CollectReport = ihook.pytest_make_collect_report(collector=collector)\nINTERNALERROR>                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_hooks.py\", line 512, in __call__\nINTERNALERROR>     return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\nINTERNALERROR>            ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_manager.py\", line 120, in _hookexec\nINTERNALERROR>     return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\nINTERNALERROR>            ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 167, in _multicall\nINTERNALERROR>     raise exception\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 139, in _multicall\nINTERNALERROR>     teardown.throw(exception)\nINTERNALERROR>     ~~~~~~~~~~~~~~^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/capture.py\", line 880, in pytest_make_collect_report\nINTERNALERROR>     rep = yield\nINTERNALERROR>           ^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pluggy/_callers.py\", line 121, in _multicall\nINTERNALERROR>     res = hook_impl.function(*args)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/runner.py\", line 391, in pytest_make_collect_report\nINTERNALERROR>     call = CallInfo.from_call(\nINTERNALERROR>         collect, \"collect\", reraise=(KeyboardInterrupt, SystemExit)\nINTERNALERROR>     )\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/runner.py\", line 344, in from_call\nINTERNALERROR>     result: TResult | None = func()\nINTERNALERROR>                              ~~~~^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/runner.py\", line 389, in collect\nINTERNALERROR>     return list(collector.collect())\nINTERNALERROR>                 ~~~~~~~~~~~~~~~~~^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py\", line 554, in collect\nINTERNALERROR>     self._register_setup_module_fixture()\nINTERNALERROR>     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py\", line 567, in _register_setup_module_fixture\nINTERNALERROR>     self.obj, (\"setUpModule\", \"setup_module\")\nINTERNALERROR>     ^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py\", line 280, in obj\nINTERNALERROR>     self._obj = obj = self._getobj()\nINTERNALERROR>                       ~~~~~~~~~~~~^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py\", line 551, in _getobj\nINTERNALERROR>     return importtestmodule(self.path, self.config)\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/python.py\", line 498, in importtestmodule\nINTERNALERROR>     mod = import_path(\nINTERNALERROR>         path,\nINTERNALERROR>     ...<2 lines>...\nINTERNALERROR>         consider_namespace_packages=config.getini(\"consider_namespace_packages\"),\nINTERNALERROR>     )\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/pathlib.py\", line 587, in import_path\nINTERNALERROR>     importlib.import_module(module_name)\nINTERNALERROR>     ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py\", line 88, in import_module\nINTERNALERROR>     return _bootstrap._gcd_import(name[level:], package, level)\nINTERNALERROR>            ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\nINTERNALERROR>   File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\nINTERNALERROR>   File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\nINTERNALERROR>   File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\nINTERNALERROR>   File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/_pytest/assertion/rewrite.py\", line 186, in exec_module\nINTERNALERROR>     exec(co, module.__dict__)\nINTERNALERROR>     ~~~~^^^^^^^^^^^^^^^^^^^^^\nINTERNALERROR>   File \"/Users/dhyana/DHARMIC_GODEL_CLAW/vault/AGENT_EMERGENT_WORKSPACES/MECH_INTERP_VAULT/archive/scripts/quick_test.py\", line 32, in <module>\nINTERNALERROR>     sys.exit(1)\nINTERNALERROR>     ~~~~~~~~^^^\nINTERNALERROR> SystemExit: 1\n\n================= 3 skipped, 3 warnings, 185 errors in 17.76s ==================\n",
      "stderr": "mainloop: caught unexpected SystemExit!\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 3",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "6",
      "gate_name": "PROPERTY_TESTING",
      "result": "fail",
      "duration_seconds": 1.1696147918701172,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Command failed with exit code 2",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "7",
      "gate_name": "CONTRACT_INTEGRATION",
      "result": "fail",
      "duration_seconds": 0.3283200263977051,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.5, pytest-8.4.2, pluggy-1.6.0 -- /Library/Frameworks/Python.framework/Versions/3.13/bin/python3\ncachedir: .pytest_cache\nhypothesis profile 'default'\nrootdir: /Users/dhyana/DHARMIC_GODEL_CLAW\nplugins: jaxtyping-0.3.5, asyncio-1.2.0, anyio-4.9.0, hypothesis-6.151.5, typeguard-4.4.4, cov-7.0.0\nasyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items\n\n- generated xml file: /Users/dhyana/DHARMIC_GODEL_CLAW/integration_results.xml -\n============================ no tests ran in 0.08s =============================\n",
      "stderr": "ERROR: file or directory not found: tests/integration/\n\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 4",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "8",
      "gate_name": "PERFORMANCE_REGRESSION",
      "result": "fail",
      "duration_seconds": 0.23069310188293457,
      "stdout": "",
      "stderr": "ERROR: usage: pytest [options] [file_or_dir] [file_or_dir] [...]\npytest: error: unrecognized arguments: --benchmark-compare --benchmark-json=benchmark.json\n  inifile: None\n  rootdir: /Users/dhyana/DHARMIC_GODEL_CLAW\n\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 4",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "9",
      "gate_name": "AHIMSA",
      "result": "fail",
      "duration_seconds": 0.00017786026000976562,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required files: proposal.yaml",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "10",
      "gate_name": "SATYA",
      "result": "fail",
      "duration_seconds": 3.504753112792969e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required artifacts: satya_assessment.json, claim_evidence_map.json",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "11",
      "gate_name": "CONSENT",
      "result": "fail",
      "duration_seconds": 2.9802322387695312e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required artifacts: consent_record.json, approval_signature.txt",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "12",
      "gate_name": "VYAVASTHIT",
      "result": "warn",
      "duration_seconds": 1.3113021850585938e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required artifacts: vyavasthit_assessment.json",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "13",
      "gate_name": "REVERSIBILITY",
      "result": "pass",
      "duration_seconds": 1.3113021850585938e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "14",
      "gate_name": "SVABHAAVA",
      "result": "warn",
      "duration_seconds": 1.0967254638671875e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required artifacts: svabhaava_assessment.json",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "15",
      "gate_name": "WITNESS",
      "result": "warn",
      "duration_seconds": 5.91278076171875e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required artifacts: audit_trail.jsonl, evidence_bundle_hash.sha256, witness_trail.json, evidence_hash.sha256",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "16",
      "gate_name": "SBOM_PROVENANCE",
      "result": "fail",
      "duration_seconds": 0.0053822994232177734,
      "stdout": "",
      "stderr": "/bin/sh: cyclonedx-py: command not found\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 127",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "17",
      "gate_name": "LICENSE_COMPLIANCE",
      "result": "fail",
      "duration_seconds": 0.003406047821044922,
      "stdout": "",
      "stderr": "/bin/sh: pip-licenses: command not found\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 127",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ML_DATA_PROVENANCE",
      "gate_name": "ML_DATA_PROVENANCE",
      "result": "fail",
      "duration_seconds": 7.700920104980469e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required files: DATA_PROVENANCE.md, data_manifest.json",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ML_EVAL_SUITE",
      "gate_name": "ML_EVAL_SUITE",
      "result": "fail",
      "duration_seconds": 0.3201632499694824,
      "stdout": "============================= test session starts ==============================\nplatform darwin -- Python 3.13.5, pytest-8.4.2, pluggy-1.6.0 -- /Library/Frameworks/Python.framework/Versions/3.13/bin/python3\ncachedir: .pytest_cache\nhypothesis profile 'default'\nrootdir: /Users/dhyana/DHARMIC_GODEL_CLAW\nplugins: jaxtyping-0.3.5, asyncio-1.2.0, anyio-4.9.0, hypothesis-6.151.5, typeguard-4.4.4, cov-7.0.0\nasyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 0 items\n\n============================ no tests ran in 0.06s =============================\n",
      "stderr": "ERROR: file or directory not found: tests/ml_eval/\n\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 4",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ML_MODEL_CARD",
      "gate_name": "ML_MODEL_CARD",
      "result": "fail",
      "duration_seconds": 0.00011587142944335938,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required files: MODEL_CARD.md",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ML_RISK_REGISTER",
      "gate_name": "ML_RISK_REGISTER",
      "result": "warn",
      "duration_seconds": 1.7881393432617188e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required files: AI_RISK_REGISTER.md",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ML_REPRODUCIBILITY",
      "gate_name": "ML_REPRODUCIBILITY",
      "result": "fail",
      "duration_seconds": 4.57763671875e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "Missing required files: requirements.txt, config.yaml, environment.lock",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ACCELERATOR_PLAN",
      "gate_name": "ACCELERATOR_PLAN",
      "result": "pass",
      "duration_seconds": 6.103515625e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "CUDA_COMPAT",
      "gate_name": "CUDA_COMPAT",
      "result": "pass",
      "duration_seconds": 1.0013580322265625e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "ACCELERATOR_BENCHMARKS",
      "gate_name": "ACCELERATOR_BENCHMARKS",
      "result": "pass",
      "duration_seconds": 4.482269287109375e-05,
      "stdout": "",
      "stderr": "",
      "artifacts": [],
      "error_message": "",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "SKILL_REGISTRY_SIGNED",
      "gate_name": "SKILL_REGISTRY_SIGNED",
      "result": "fail",
      "duration_seconds": 0.004266977310180664,
      "stdout": "",
      "stderr": "/bin/sh: python: command not found\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 127",
      "exception_applied": false,
      "exception_reason": ""
    },
    {
      "gate_id": "SKILL_SUPPLY_CHAIN_SCAN",
      "gate_name": "SKILL_SUPPLY_CHAIN_SCAN",
      "result": "fail",
      "duration_seconds": 0.0033800601959228516,
      "stdout": "",
      "stderr": "/bin/sh: python: command not found\n",
      "artifacts": [],
      "error_message": "Command failed with exit code 127",
      "exception_applied": false,
      "exception_reason": ""
    }
  ],
  "evidence_bundle_hash": "0671784784857c5d32579c5bde4e931f8c9ef09617df73359fccbde822b06164",
  "evidence_signature": "",
  "signature_method": "hmac-sha256",
  "signature_key_id": "",
  "signature_required": true,
  "signature_present": false,
  "emergency_bypass": false,
  "emergency_reason": "",
  "emergency_approver": "",
  "exceptions_applied": []
}